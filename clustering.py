import csv
import numpy
from config import config as cfg
from scipy.cluster.hierarchy import *
from scipy.spatial.distance import pdist
import pygraphviz as pg
from collections import OrderedDict, Counter
import util
import DBModel
from Ticket import Ticket


class LabelledClusterNode(ClusterNode):
    """
    Custom ClusterNode class for use in binary or n-ary trees.
    """
    def __init__(self, cn):
        ClusterNode.__init__(self, cn.get_id(), cn.get_left(), cn.get_right(), 0)
        self.label = None
        self.parent = None
        self.children_list = []
        self.num_leaf_nodes = 1
        self.head = None
        self.ground_truth = []


class LabelledTree:
    """
    Data structure representing a tree and its meta data.
    self.tree is first created by replicating the scipy binary tree generated by Linkage.
    Each node is then transformed into a LabelledClusterNode, which inherits the original scipy node class.
    Next, labels are generated for each leaf node based on node id (which corresponds to the index of the data)
    After all leaves are labelled, the parents are labelled according to the intersection of its children's labels.
    This labelled binary tree is then transformed into an n-ary tree, which can be drawn with pygraphviz.
    """
    def __init__(self, root, system_name, list_of_tickets):
        self.tree = LabelledClusterNode(root)
        self.list_of_tickets = list_of_tickets
        self.system_name = system_name

    @staticmethod
    def build_keyword_to_weight_dict_from_ticket(ticket_of_interest):
        list_nonzero_weights = ticket_of_interest.nonzero_vector
        list_keywords = ticket_of_interest.keywords

        kw_to_weight_dict = {}
        for i in range(len(list_nonzero_weights)):
            kw_to_weight_dict[list_keywords[i]] = list_nonzero_weights[i]

        return kw_to_weight_dict

    def generate_keywords_label(self, nid):
        keyword_weights = self.build_keyword_to_weight_dict_from_ticket(ticket_of_interest=self.list_of_tickets[nid])

        # Sort according to value
        return OrderedDict(sorted(keyword_weights.items(), key=lambda t: t[1], reverse=True)).keys()

    def create_label_tree(self):
        # DFS through scipy tree and convert to label leaf nodes according to T
        stack = [self.tree]
        parents = []
        while stack:
            node = stack.pop()
            nid = node.get_id()

            # This checks if left is None, which would make it a leaf
            if node.is_leaf():
                node.label = self.generate_keywords_label(nid)
            else:
                node.left = LabelledClusterNode(node.get_left())
                left_child = node.get_left()

                stack.append(left_child)
                left_child.parent = node
                parents.append(node)

            if node.get_right() is not None:
                node.right = LabelledClusterNode(node.get_right())
                right_child = node.get_right()

                stack.append(right_child)
                right_child.parent = node

        # Now go to each non-leaf node and label as intersection of all leaf nodes below it
        i = len(parents) - 1
        while i >= 0:
            right_child = parents[i].get_right()
            left_child = parents[i].get_left()
            if right_child is None:
                parents[i].label = left_child.label
            else:
                intersection = set.intersection(set(left_child.label), set(right_child.label))
                if not intersection:
                    parents[i].label = ['unknown']
                else:
                    parents[i].label = list(intersection)
            i -= 1

    def generate_bt_stats(self, node):
        if node is None:
            return 0
        if node.is_leaf():
            return 1
        return self.generate_bt_stats(node.get_left()) + self.generate_bt_stats(node.get_right())

    def generate_leaf_statistics(self, node, cache):
        if cache[node.get_id()] != 0:
            return cache[node.get_id()]

        if len(node.children_list) == 0:
            cache[node.get_id()] = 1
            return 1

        result = 0
        for child in node.children_list:
            result += self.generate_leaf_statistics(child, cache)
        cache[node.get_id()] = result
        return result

    def create_nary_from_label_tree(self):
        queue = [self.tree]

        while queue:
            node = queue.pop(0)
            left_child = node.get_left()
            right_child = node.get_right()
            self.merge_or_add_child(left_child, node, queue)
            self.merge_or_add_child(right_child, node, queue)

        # Generate statistics of each node by recursive DFS
        cache = Counter()
        stack = [self.tree]
        while stack:
            node = stack.pop()
            node.num_leaf_nodes = self.generate_leaf_statistics(node, cache)
            for child in node.children_list:
                stack.append(child)

        #print self.tree.num_leaf_nodes

    @staticmethod
    def merge_or_add_child(child, node, queue):
        if child is None:
            return
        queue.append(child)

        # A unique node was found, so it is set as head of sequence. This starts off the propagation.
        if node.head is None:
            node.head = node

        # A duplicate child was found, so its head will be set to this node's head (set previously).
        # This step propagates the head's reference down the tree until it hits a unique node.
        # When a unique node is found, it will add that unique node to the head's list, and the process starts over.
        if str(child.label) == str(node.label):
            child.head = node.head
        else:
            node.head.children_list.append(child)


def draw_binary_tree(Tree, filepath, max_tree_size):
    A = pg.AGraph(directed=True, strict=True)

    level = 0
    queue = [Tree.tree]
    while queue:
        node = queue.pop(0)
        node_string = str(node.label) + '\n' + str(Tree.generate_bt_stats(node))

        if node.parent is not None:
            parent_string = str(node.parent.label) + '\n' + str(Tree.generate_bt_stats(node.parent))
            A.add_edge(parent_string, node_string)

        level += 1
        if node.get_left() is not None:
            queue.append(node.get_left())
        if node.get_right() is not None:
            queue.append(node.get_right())
        if level >= max_tree_size:
            break

    dot_path = util.cwd + '/dot' + filepath
    util.ensure_path_exists(dot_path)
    A.write('{}{} BT.dot'.format(dot_path, Tree.system_name))
    A.layout(prog='dot')
    A.draw('{}{} BT.png'.format(dot_path, Tree.system_name))
    print "[clustering] : Created binary tree at path {}.".format('{}{} BT.png'.format(dot_path, Tree.system_name))


def create_node_string(node):
    node_string = node.label
    return str(node_string) + '\n' + str(node.num_leaf_nodes)


def draw_nary_tree(Tree, max_tree_size, correlation, c='none'):
    A = pg.AGraph(directed=True, strict=True)

    # Get value thats 1% of total nodes in tree
    num_leaf_nodes_cutoff = int(0.01 * Tree.tree.num_leaf_nodes)
    print "[clustering] : Leaf node cutoff: {}.".format(num_leaf_nodes_cutoff)

    # BFS trough the tree and draw first 300 nodes
    level = 0
    queue = [Tree.tree]
    while queue:
        node = queue.pop(0)
        level += 1

        node_string = create_node_string(node)

        for child in node.children_list:
            # Skip this node if it doesn't meet the 1% cutoff requirement
            if child.num_leaf_nodes < num_leaf_nodes_cutoff:
                continue

            # Create child string so only words not in parent are displayed.
            child_string = create_node_string(child)
            A.add_edge((node_string, child_string))
            queue.append(child)

        if level >= max_tree_size:
            break

    dot_path = util.generate_meta_path(Tree.system_name, 'dot', c)
    util.ensure_path_exists(dot_path)
    A.write('{}{} NT.dot'.format(dot_path, Tree.system_name))
    A.layout(prog='dot')
    A.draw('{}{} NT Score={}.png'.format(dot_path, Tree.system_name, correlation))
    print "[clustering] : Created n-ary tree at path {}.".format('{}{} NT Score={}.png'.format(dot_path,
                                                                                               Tree.system_name,
                                                                                               correlation))


def cluster(system_name):
    class_clustering_filter = cfg.class_clustering_filter
    systems_filter = cfg.systems_filter
    max_tree_size = cfg.max_tree_size

    if class_clustering_filter == 'none':
        cluster_by_all(system_name, max_tree_size)
    else:
        cluster_by_filter(system_name, systems_filter, class_clustering_filter, max_tree_size)
    print "[status] : Generated tree drawings."


def cluster_by_all(system_name, max_tree_size):
    vector_path = util.generate_meta_path(system_name, 'vectors')
    filename = vector_path + system_name + '_vectors.csv'

    with open(filename, 'r') as csvfile:
        reader = csv.DictReader(csvfile)
        list_of_ticket_dicts = [rows for rows in reader]

    if len(list_of_ticket_dicts) < 1:
        print "[warning] : Not enough tickets to generate clusters. Skipping..."
        return

    # Create list of keyword weights, keeping string format
    list_of_weights = [ticket_dict['vector'] for ticket_dict in list_of_ticket_dicts]

    # Construct matrix from the list of keyword dictionaries
    tickets_to_weights_matrix = construct_matrix(list_of_weights)

    if tickets_to_weights_matrix.shape[0] < 2:
        print "[warning] : Not enough tickets to generate clusters. Skipping..."
        return

    method = cfg.cluster_similarity_method
    metric = cfg.distance_metric

    Y = pdist(tickets_to_weights_matrix, metric=metric)
    Y = Y[~numpy.isnan(Y)]

    Z = linkage(Y, method=method, metric=metric)

    correlation, coph_dists = cophenet(Z, Y)

    print "[{}] : Cophenetic Correlation: {}".format(system_name, correlation)

    root_node = to_tree(Z, rd=False)
    list_of_tickets = build_ticket_list(list_of_ticket_dicts)
    Tree = LabelledTree(root_node, system_name, list_of_tickets)
    Tree.create_label_tree()

    #draw_binary_tree(Tree, tree_path, max_tree_size)
    Tree.create_nary_from_label_tree()
    draw_nary_tree(Tree, max_tree_size, correlation)

    print "[{}] : Tree generated.".format(system_name, system_name)


def build_ticket_list(list_of_ticket_dicts):
    ticket_list = []
    for ticket_dict in list_of_ticket_dicts:
        desc = ticket_dict['description']
        id = ticket_dict['id']
        classes = ticket_dict['classification']
        system = ticket_dict['system']
        vector = [float(x) for x in ticket_dict['vector'].split(' ')]
        keywords = [word for word in ticket_dict['keywords'].split(' ')]
        t = Ticket(id, desc, classes, system, vector, keywords)
        ticket_list.append(t)

    return ticket_list


def construct_matrix(list_of_weights):
    # Build a numpy matrix of m x n, where m is number of documents and n is number of keywords
    tickets_to_weights_matrix = numpy.zeros((len(list_of_weights), len(list_of_weights[0].split(' '))))

    m = len(list_of_weights)
    # Construct matrix of weights as integer only numpy matrix
    for i in range(m):
        list_of_float_weights = [float(x) for x in list_of_weights[i].split(' ')]
        n = len(list_of_float_weights)

        for j in range(n):
            tickets_to_weights_matrix[i, j] = list_of_float_weights[j]

    print "[status] : Shape is {}".format(tickets_to_weights_matrix.shape)

    return tickets_to_weights_matrix


def cluster_by_filter(system_name, topology_filter, clustering_filter, max_tree_size):
    classes_to_keep = set()

    if topology_filter == 'none':
        selection = DBModel.LFF_Keywords.select()
    else:
        selection = DBModel.LFF_Keywords.select_by_system(system_name)

    # Create list of classes of to be clustered according to filter
    for row in selection:
        classes = row.classification.split(' ')

        for c in classes:
            c = c.encode()
            if len(c) < 2 or c in classes_to_keep:
                continue
            elif clustering_filter is None:
                classes_to_keep.add(c)
            elif c.startswith(clustering_filter):
                classes_to_keep.add(c)

    # Add the filter of interest to build a non-truth cluster
    classes_to_keep.add(clustering_filter)

    for c in classes_to_keep:
        # Load file assuming it was created previously for this class
        vector_path = util.generate_meta_path(system_name, 'vectors', c)
        filename = vector_path + system_name + '_vectors.csv'

        with open(filename, 'r') as csvfile:
            reader = csv.DictReader(csvfile)
            list_of_ticket_dicts = [rows for rows in reader]

        if len(list_of_ticket_dicts) < 1:
            print "[warning] : Not enough tickets to generate clusters. Skipping..."
            continue

        # Create list of keyword weights, keeping string format
        list_of_weights = [ticket_dict['vector'] for ticket_dict in list_of_ticket_dicts]

        # Construct matrix from the list of keyword dictionaries
        tickets_to_weights_matrix = construct_matrix(list_of_weights)

        if tickets_to_weights_matrix.shape[0] < 2:
            print "[warning] : Not enough tickets to generate clusters. Skipping..."
            continue

        method = cfg.cluster_similarity_method
        metric = cfg.distance_metric

        Y = pdist(tickets_to_weights_matrix, metric=metric)
        Y = Y[~numpy.isnan(Y)]

        Z = linkage(Y, method=method, metric=metric)

        correlation, coph_dists = cophenet(Z, Y)

        print "[{}:{}] : Cophenetic Correlation: {}".format(system_name, c, correlation)

        list_of_tickets = build_ticket_list(list_of_ticket_dicts)
        root_node = to_tree(Z, rd=False)
        Tree = LabelledTree(root_node, system_name, list_of_tickets)
        Tree.create_label_tree()

        # draw_binary_tree(Tree, tree_path, max_tree_size)
        Tree.create_nary_from_label_tree()
        draw_nary_tree(Tree, max_tree_size, correlation, c)

        print "[{}:{}] : Tree generated.".format(system_name, c)
